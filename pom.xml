<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>org.self.data.spark.common</groupId>
    <artifactId>spark-data-etl-common</artifactId>
    <packaging>pom</packaging>
    <version>1.0.0</version>
    <modules>
        <module>data-common</module>
        <module>data-beans</module>
        <module>data-engine</module>
        <module>data-distributed-storage</module>
        <module>data-reader</module>
        <module>data-validation</module>
    </modules>
    <properties>
        <global.current.version>1.0.0</global.current.version>
        <hadoop.version>2.7.1</hadoop.version>
        <spark.version>3.0.0</spark.version>
        <scala.major.version>2.12</scala.major.version>
        <hive.version>2.3.1</hive.version>
        <jackson-databind.version>2.6.7</jackson-databind.version>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <avro.version>1.8.0</avro.version>
        <parquet.version>1.8.1</parquet.version>
        <guava.version>11.0.2</guava.version>
        <slf4j.version>1.7.7</slf4j.version>
        <databricks.csv.version>1.5.0</databricks.csv.version>
        <java.version>1.8</java.version>
        <!-- Put the Scala version of the cluster -->
        <!-- CDH 5.7.x supports 2.10.x only 2.11 is not supported check http://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_rn_spark_ki.html -->
        <scala.minor.version>4</scala.minor.version>
        <scoverage.plugin.version>1.3.0</scoverage.plugin.version>
        <spark-testing-base.version>0.3.3</spark-testing-base.version>
        <spark-avro.version>2.0.1</spark-avro.version>
        <spark-testing-base>0.3.3</spark-testing-base>
        <typesafe.config.version>1.4.0</typesafe.config.version>
        <log4j2.version>2.13.3</log4j2.version>
        <log4j2.scala.version>12.0</log4j2.scala.version>
        <snamkeyaml.version>1.27</snamkeyaml.version>
        <typesafe.config.version>1.4.0</typesafe.config.version>
        <commons.collections.version>4.4</commons.collections.version>
        <commons.lang3.version>3.10</commons.lang3.version>
        <commons.io.version>2.4</commons.io.version>

    </properties>
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.self.data.spark.common</groupId>
                <artifactId>data-beans</artifactId>
                <version>${global.current.version}</version>
            </dependency>
            <dependency>
                <groupId>org.self.data.spark.common</groupId>
                <artifactId>data-reader</artifactId>
                <version>${global.current.version}</version>
            </dependency>
            <dependency>
                <groupId>org.self.data.spark.common</groupId>
                <artifactId>data-common</artifactId>
                <version>${global.current.version}</version>
            </dependency>
            <dependency>
                <groupId>org.self.data.spark.common</groupId>
                <artifactId>data-distributed-storage</artifactId>
                <version>${global.current.version}</version>
            </dependency>
            <dependency>
                <groupId>org.self.data.spark.common</groupId>
                <artifactId>data-validation</artifactId>
                <version>${global.current.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-sql_${scala.major.version}</artifactId>
                <version>${spark.version}</version>
                <!--<scope>provided</scope>-->
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-core_${scala.major.version}</artifactId>
                <version>${spark.version}</version>
                <!--<scope>provided</scope>-->
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-hive_${scala.major.version}</artifactId>
                <version>${spark.version}</version>
                <!--<scope>provided</scope>-->
            </dependency>
            <dependency>
                <groupId>com.databricks</groupId>
                <artifactId>spark-csv_${scala.major.version}</artifactId>
                <version>${databricks.csv.version}</version>
            </dependency>
            <dependency>
                <groupId>org.scalatest</groupId>
                <artifactId>scalatest_${scala.major.version}</artifactId>
                <version>3.0.0-M15</version>
                <scope>test</scope>
            </dependency>
            <dependency>
                <groupId>org.scalactic</groupId>
                <artifactId>scalactic_${scala.major.version}</artifactId>
                <version>3.0.0-M15</version>
                <scope>test</scope>
            </dependency>
            <dependency>
                <groupId>com.github.scopt</groupId>
                <artifactId>scopt_${scala.major.version}</artifactId>
                <version>3.5.0</version>
            </dependency>
            <dependency>
                <groupId>com.amazonaws</groupId>
                <artifactId>aws-java-sdk</artifactId>
                <version>1.10.6</version>
            </dependency>
            <dependency>
                <groupId>mysql</groupId>
                <artifactId>mysql-connector-java</artifactId>
                <version>5.1.40</version>
            </dependency>
            <dependency>
                <groupId>org.json</groupId>
                <artifactId>json</artifactId>
                <version>20090211</version>
            </dependency>

            <dependency>
                <groupId>com.fasterxml.jackson.core</groupId>
                <artifactId>jackson-databind</artifactId>
                <version>${jackson-databind.version}</version>
                <scope>provided</scope>
            </dependency>
            <dependency>
                <groupId>org.yaml</groupId>
                <artifactId>snakeyaml</artifactId>
                <version>${snamkeyaml.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.commons</groupId>
                <artifactId>commons-collections4</artifactId>
                <version>${commons.collections.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.commons</groupId>
                <artifactId>commons-lang3</artifactId>
                <version>${commons.lang3.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.logging.log4j</groupId>
                <artifactId>log4j-api</artifactId>
                <version>${log4j2.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.logging.log4j</groupId>
                <artifactId>log4j-core</artifactId>
                <version>${log4j2.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.logging.log4j</groupId>
                <artifactId>log4j-api-scala_2.11</artifactId>
                <version>${log4j2.scala.version}</version>
            </dependency>
            <dependency>
                <groupId>org.slf4j</groupId>
                <artifactId>slf4j-log4j12</artifactId>
                <version>${slf4j.version}</version>
            </dependency>
            <dependency>
                <groupId>com.typesafe</groupId>
                <artifactId>config</artifactId>
                <version>${typesafe.config.version}</version>
            </dependency>
            <dependency>
                <groupId>org.scala-lang</groupId>
                <artifactId>scala-library</artifactId>
                <version>${scala.major.version}.${scala.minor.version}</version>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <build>
        <pluginManagement>
            <plugins>
                <plugin>
                    <artifactId>maven-shade-plugin</artifactId>
                    <version>2.2</version>
                    <configuration>
                        <finalName>spark-data-etl-common</finalName>
                        <appendAssemblyId>false</appendAssemblyId>
                    </configuration>
                    <executions>
                        <execution>
                            <id>jar-with-dependencies</id>
                            <phase>package</phase>
                            <goals>
                                <goal>shade</goal>
                            </goals>
                            <configuration>
                                <shadedArtifactAttached>true</shadedArtifactAttached>
                                <!--<shadedClassifierName>jar-with-deps</shadedClassifierName>-->
                                <filters>
                                    <filter>
                                        <artifact>*:*</artifact>
                                        <excludes>
                                            <exclude>META-INF/*.SF</exclude>
                                            <exclude>META-INF/*.DSA</exclude>
                                            <exclude>META-INF/*.RSA</exclude>
                                        </excludes>
                                    </filter>
                                </filters>
                            </configuration>
                        </execution>
                    </executions>
                </plugin>
            </plugins>
        </pluginManagement>
    </build>
</project>